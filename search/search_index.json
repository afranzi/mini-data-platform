{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The Mini Data Platform","text":""},{"location":"#the-concept","title":"The concept","text":"<p>In the evolving landscape of data management and infrastructure automation, the ability to efficiently deploy and manage data platforms is essential for any organization looking to leverage data-driven insights. The mini data platform cluster project that embodies the spirit of innovation and learning in the fields of Infrastructure as Code (IaC), Data Engineering, and Operations (Ops).</p> <p></p> <p>At the heart of this project lies a carefully curated stack comprising Terraform, Minikube, ArgoCD, and Airflow. Each tool has been selected for its strength in automating and managing infrastructure, orchestrating deployments, and scheduling complex workflows, respectively. Together, they form a robust framework that enables users to deploy a miniature yet fully-functional data platform cluster with ease.</p> <p>Learning purpose</p> <p>This project serves a dual purpose. Firstly, it is a practical guide that demonstrates the simplicity and efficiency of using modern DevOps tools to set up a data platform. Secondly, it acts as a learning platform for enthusiasts and professionals alike who wish to deepen their understanding and enhance their skills in IaC(1), Data Engineering, and Ops.</p> <ol> <li>IaC: Infrastructure as Code</li> </ol> <ul> <li> <p> Kubernetes (K8s)</p> <p>Define architecture in a serverless approach and running in minutes</p> </li> <li> <p> Terraform</p> <p>Learn how to define Infrastructure as Code</p> <p> Getting started</p> </li> <li> <p> ArgoCD</p> <p>Declarative &amp; GitOps continuous delivery tool for Kubernetes.</p> </li> <li> <p> Airflow</p> <p>Define &amp; orchestrate Data Pipelines</p> </li> </ul>"},{"location":"#execution","title":"Execution","text":"<p>The main advantage about using Terraform for this project is the simplicity of deploying it.</p> <pre><code>cd terraform/main\nterraform init\nterraform apply\n</code></pre> <p>In case of doubt, check the  Terraform section.</p>"},{"location":"#literature","title":"Literature","text":"<p>This section compiles a selection of articles and resources that were invaluable in the development of the mini data platform cluster project. It features links to comprehensive readings on Terraform, Minikube, ArgoCD, and Airflow, each chosen for its clear explanations, practical advice, and relevance to integrating and utilizing these tools effectively. We extend our gratitude to the authors of these resources for their insights and contributions to the community.</p> <ul> <li>Installing ArgoCD on Minikube and deploying a test application</li> </ul> <p> Acknowledge</p> <p>We acknowledge and appreciate the effort and expertise of each author whose work has guided us. As our project grows and adapts, we will continue to update this section with new findings and articles that reflect our ongoing learning journey and the contributions of experts in the field.</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>Tip</p> <p>This section aims to brainstorm the potential roadmap to keep the Mini Data Platform project evolving.</p> <ul> <li> Define full project with  Terraform.</li> <li> Deploy  Airflow in K8s via  ArgoCD.</li> <li> Provide a Postgres DB</li> <li> Automate documentation<ul> <li> Terraform docs</li> <li> Helms docs</li> <li> Airflow docs</li> <li> DBT docs</li> </ul> </li> <li> <p> Python DAG retrieving daily exchange rates data from https://fixer.io/ into the K8s postgres db.</p> <ul> <li>Showcase how to execute a K8sPodOperator to execute Python code.</li> </ul> </li> <li> <p> DBT DAG processing the exchange rates</p> <ul> <li>Showcase how to encapsulate and execute DBT Core as a K8sPodOperator</li> </ul> </li> <li> <p> DBT Elementary Report Website</p> <ul> <li>Showcase how to host and provide a static website inside K8s.</li> </ul> </li> <li> <p> K8s Certificates: Solve <code>Not Secure</code> issue with nginx without due fake certificates.</p> </li> </ul>"},{"location":"helms/airflow/","title":"Airflow","text":"<p>Community Chart</p> <p>In our project, we use the Airflow Community Helm chart to deploy Airflow on our Minikube cluster.</p> <p>This chart is our favorite one because it's flexible and easy to use, making it perfect for getting Airflow up running in a Kubernetes environment like ours.</p>"},{"location":"helms/airflow/#setup","title":"Setup","text":"<p>For the actual deployment into our Kubernetes cluster, we're using  ArgoCD. It's a tool that helps us deploy applications automatically, following the best practices of GitOps. This means we can manage our Airflow setup with code, making changes easily and keeping everything up to date without hassle.</p> <p>Using ArgoCD not only makes our lives easier by automating deployment tasks but also keeps our project tidy and well-organized. It's a smart way to handle deployments, giving us more time to focus on making our data platform better.</p> <p></p> <p>The most important properties when defining our Airflow values are:</p> <ul> <li> <p> <code>dags.gitSync.repo</code></p> <p>Github repo containing our Airflow DAGs code. Airflow dags-git-sync sidecars will be fetching new code periodically from it. So all code pushed there will be automatically deployed.</p> </li> <li> <p> <code>dags.gitSync.repoSubPath</code></p> <p>Github folder containing our DAGs code. This property is mandatory to use in this project since we are defining multiple tools in it (i.e. K8s, terraform, Helms).</p> </li> </ul>"},{"location":"helms/airflow/#requirements","title":"Requirements","text":"Repository Name Version https://airflow-helm.github.io/charts airflow 8.8.0"},{"location":"helms/airflow/#values","title":"Values","text":"Key Type Default Description airflow.airflow.config.AIRFLOW__API__AUTH_BACKENDS string <code>\"airflow.api.auth.backend.basic_auth\"</code> airflow.airflow.config.AIRFLOW__CORE__CHECK_SLAS string <code>\"False\"</code> airflow.airflow.config.AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION string <code>\"True\"</code> airflow.airflow.config.AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG int <code>1</code> airflow.airflow.config.AIRFLOW__CORE__MIN_SERIALIZED_DAG_UPDATE_INTERVAL int <code>150</code> airflow.airflow.config.AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS string <code>\"False\"</code> airflow.airflow.config.AIRFLOW__LOGGING__REMOTE_LOGGING string <code>\"False\"</code> airflow.airflow.config.AIRFLOW__WEBSERVER__AUTHENTICATE string <code>\"False\"</code> airflow.airflow.config.AIRFLOW__WEBSERVER__BASE_URL string <code>\"https://airflow.data\"</code> airflow.airflow.config.AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX string <code>\"True\"</code> airflow.airflow.config.AIRFLOW__WEBSERVER__EXPOSE_CONFIG string <code>\"False\"</code> airflow.airflow.config.AIRFLOW__WEBSERVER__HIDE_PAUSED_DAGS_BY_DEFAULT string <code>\"True\"</code> airflow.airflow.executor string <code>\"CeleryExecutor\"</code> airflow.airflow.image.repository string <code>\"apache/airflow\"</code> airflow.airflow.image.tag string <code>\"2.8.2-python3.10\"</code> airflow.createUserJob.applyCustomEnv bool <code>false</code> airflow.createUserJob.useHelmHooks bool <code>false</code> airflow.dags.gitSync.branch string <code>\"main\"</code> airflow.dags.gitSync.enabled bool <code>true</code> airflow.dags.gitSync.repo string <code>\"https://github.com/afranzi/mini-data-platform.git\"</code> airflow.dags.gitSync.repoSubPath string <code>\"airflow\"</code> airflow.dags.gitSync.resources.requests.cpu string <code>\"50m\"</code> airflow.dags.gitSync.resources.requests.memory string <code>\"64Mi\"</code> airflow.dags.gitSync.revision string <code>\"HEAD\"</code> airflow.dags.gitSync.syncWait int <code>60</code> airflow.ingress.apiVersion string <code>\"networking.k8s.io/v1\"</code> airflow.ingress.enabled bool <code>true</code> airflow.ingress.web.host string <code>\"airflow.data\"</code> airflow.ingress.web.ingressClassName string <code>\"nginx\"</code> airflow.migrateDatabaseJob.applyCustomEnv bool <code>false</code> airflow.migrateDatabaseJob.jobAnnotations.\"argocd.argoproj.io/hook\" string <code>\"Sync\"</code> airflow.migrateDatabaseJob.useHelmHooks bool <code>false</code> airflow.postgresql.enabled bool <code>true</code> airflow.redis.cluster.enabled bool <code>false</code> airflow.redis.cluster.slaveCount int <code>1</code> airflow.redis.enabled bool <code>true</code> airflow.redis.image.tag string <code>\"7.2.4-debian-12-r9\"</code> airflow.redis.master.persistence.enabled bool <code>false</code> airflow.redis.master.persistence.size string <code>\"2Gi\"</code> airflow.redis.master.persistence.storageClass string <code>\"\"</code> airflow.redis.master.resources.requests.cpu string <code>\"10m\"</code> airflow.redis.master.resources.requests.memory string <code>\"32Mi\"</code> airflow.redis.slave.persistence.enabled bool <code>false</code> airflow.redis.slave.persistence.size string <code>\"8Gi\"</code> airflow.redis.slave.persistence.storageClass string <code>\"\"</code> airflow.redis.slave.resources.requests.cpu string <code>\"10m\"</code> airflow.redis.slave.resources.requests.memory string <code>\"32Mi\"</code> airflow.scheduler.resources.limits.cpu string <code>\"1000m\"</code> airflow.scheduler.resources.limits.memory string <code>\"1Gi\"</code> airflow.scheduler.resources.requests.cpu string <code>\"1000m\"</code> airflow.scheduler.resources.requests.memory string <code>\"512Mi\"</code> airflow.workers.enabled bool <code>true</code> airflow.workers.logCleanup.enabled bool <code>true</code> airflow.workers.logCleanup.resources.requests.cpu string <code>\"10m\"</code> airflow.workers.logCleanup.resources.requests.memory string <code>\"32Mi\"</code> airflow.workers.logCleanup.retentionMinutes int <code>21600</code> airflow.workers.podDisruptionBudget.apiVersion string <code>nil</code> airflow.workers.podDisruptionBudget.enabled bool <code>true</code> airflow.workers.podDisruptionBudget.maxUnavailable string <code>\"20%\"</code> airflow.workers.replicas int <code>1</code> airflow.workers.resources.requests.cpu string <code>\"256m\"</code> airflow.workers.resources.requests.memory string <code>\"1Gi\"</code>"},{"location":"terraform/main/","title":"Mini Data Platform","text":"<p>This project aims to showcase the value and capabilities to deploy a local K8s cluster with the minimum Data Platform stack we would start in any company. This means having K8s with ArgoCD &amp; Airflow.</p> <p>Terraform setup</p> <p>This section has been generated with the terraform-docs pre-commit repo.</p>"},{"location":"terraform/main/#setup","title":"Setup","text":"<p>For the mini-data-platform deployment we will require:</p> <ul> <li> minikube to deploy the K8s cluster</li> <li> tfenv to manage our Terraform version</li> <li> colima for running docker</li> <li> qemu driver for K8S VM creation</li> <li> OpenLens to interact with K8s</li> <li> trivy for security checks</li> </ul> setup.sh<pre><code>brew install docker\nbrew install colima\nbrew install minikube\nbrew install trivy\n# Configure Terraform\nbrew install tfenv\ntfenv install latest\ntfenv use latest\n# extras\nbrew install --cask openlens\n</code></pre>"},{"location":"terraform/main/#qemu-networking","title":"Qemu Networking","text":"<p>Info</p> <p>The QEMU driver has two networking options: socket_vmnet and builtin. socket_vmnet will give you full minikube networking functionality, such as the service and tunnel commands. See: docs</p> qemu_setup.sh<pre><code>minikube start --driver=qemu --download-only\nbrew install socket_vmnet\nbrew tap homebrew/services\nHOMEBREW=$(which brew) &amp;&amp; sudo ${HOMEBREW} services start socket_vmnet\n</code></pre>"},{"location":"terraform/main/#configure-local-network","title":"Configure local network","text":"<p>Since we take advantage of the ingress add-on, we must configure our local hosts and resolvers to enable us to browser our applications using our own local domain.</p> <p>Tip</p> <p>The default configuration exposes all the endpoints into the <code>*.data</code> domain. (i.e. argocd.data &amp; airflow.data).</p> <p>Once the minikube cluster is deployed via terraform, we will obtain its ip with the following command: <pre><code>$ minikube ip -p data\n192.168.105.4\n</code></pre></p> <p>Then, we will provide the new resolver in addition of updating the hosts file.</p> /etc/resolver/minikube-data<pre><code>domain data\nnameserver 192.168.105.4\nsearch_order 1\ntimeout 5\n</code></pre> /etc/hosts<pre><code>192.168.105.4 argocd.data\n192.168.105.4 airflow.data\n</code></pre>"},{"location":"terraform/main/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.7.4 argocd 6.0.3 helm ~&gt; 2.12.1 kubernetes ~&gt; 2.26.0 minikube ~&gt; 0.3.10"},{"location":"terraform/main/#providers","title":"Providers","text":"<p>No providers.</p>"},{"location":"terraform/main/#modules","title":"Modules","text":"Name Source Version application ../modules/k8s/argocd/application n/a application_db ../modules/k8s/argocd/application n/a argocd ../modules/k8s/argocd/server n/a cluster ../modules/k8s/minicluster n/a namespace ../modules/k8s/namespace n/a project ../modules/k8s/argocd/project n/a"},{"location":"terraform/main/#resources","title":"Resources","text":"<p>No resources.</p>"},{"location":"terraform/main/#inputs","title":"Inputs","text":"<p>No inputs.</p>"},{"location":"terraform/main/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"terraform/modules/k8s/minicluster/","title":"Minicluster","text":""},{"location":"terraform/modules/k8s/minicluster/#minicluster","title":"MiniCluster","text":"<p>This module aims to deploy a Kubernetes cluster by using minikube</p>"},{"location":"terraform/modules/k8s/minicluster/#requirements","title":"Requirements","text":"<p>Since we will be deploying ArgoCD &amp; Airflow in the local k8s cluster, we should provide at least 8GB &amp; 4 CPUs.</p> <p>minikube drivers</p> <p>The docker driver does not support the ingress add-on so we advice to use the qemu driver in M1 &amp; M2 Macs, since hyperkit is not supported in arm architecture.</p>"},{"location":"terraform/modules/k8s/minicluster/#requirements_1","title":"Requirements","text":"Name Version terraform &gt;= 1.7.4 minikube ~&gt; 0.3.10"},{"location":"terraform/modules/k8s/minicluster/#providers","title":"Providers","text":"Name Version minikube ~&gt; 0.3.10"},{"location":"terraform/modules/k8s/minicluster/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"terraform/modules/k8s/minicluster/#resources","title":"Resources","text":"Name Type minikube_cluster.cluster resource"},{"location":"terraform/modules/k8s/minicluster/#inputs","title":"Inputs","text":"Name Description Type Default Required cpus Amount of CPUs to allocate to Kubernetes <code>number</code> <code>4</code> no driver Minikube driver <code>string</code> n/a yes memory Amount of RAM to allocate to Kubernetes <code>string</code> <code>\"8g\"</code> no name Cluster name <code>string</code> n/a yes network Network to run minikube with <code>string</code> <code>null</code> no"},{"location":"terraform/modules/k8s/minicluster/#outputs","title":"Outputs","text":"Name Description client_certificate Client certificate used in cluster client_key Client key for cluster cluster_ca_certificate Certificate authority for cluster host The host name for the cluster"},{"location":"terraform/modules/k8s/argocd/application/","title":"Application","text":""},{"location":"terraform/modules/k8s/argocd/application/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.7.4 argocd 6.0.3"},{"location":"terraform/modules/k8s/argocd/application/#providers","title":"Providers","text":"Name Version argocd 6.0.3"},{"location":"terraform/modules/k8s/argocd/application/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"terraform/modules/k8s/argocd/application/#resources","title":"Resources","text":"Name Type argocd_application.apps resource"},{"location":"terraform/modules/k8s/argocd/application/#inputs","title":"Inputs","text":"Name Description Type Default Required argocd_namespace Namespace where the ArgoCD server has been deployed <code>string</code> n/a yes chart Repository path with helm <code>string</code> <code>null</code> no cluster_name Cluster url <code>string</code> <code>\"https://kubernetes.default.svc\"</code> no history_limit History limit <code>number</code> <code>3</code> no name Application name <code>string</code> n/a yes namespace K8s namespace to deploy application <code>string</code> n/a yes parameters Helm parameters which are passed to the helm template command upon manifest generation <code>map(string)</code> <code>{}</code> no path Repository path with helm <code>string</code> <code>\"\"</code> no project_name ArgoCD Project name <code>string</code> n/a yes repo_url Repository URL <code>string</code> n/a yes target_revision Target revision to retrieve from Git <code>string</code> <code>\"HEAD\"</code> no value_files Helm value files <code>list(string)</code> <pre>[  \"values.yaml\"]</pre> no values Helm values which are passed to the helm template command upon manifest generation <code>any</code> <code>null</code> no"},{"location":"terraform/modules/k8s/argocd/application/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"terraform/modules/k8s/argocd/project/","title":"Project","text":""},{"location":"terraform/modules/k8s/argocd/project/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.7.4 argocd 6.0.3"},{"location":"terraform/modules/k8s/argocd/project/#providers","title":"Providers","text":"Name Version argocd 6.0.3"},{"location":"terraform/modules/k8s/argocd/project/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"terraform/modules/k8s/argocd/project/#resources","title":"Resources","text":"Name Type argocd_project.main resource"},{"location":"terraform/modules/k8s/argocd/project/#inputs","title":"Inputs","text":"Name Description Type Default Required cluster_resource_allowlist Resource allowlist <pre>list(object({    group : string    kind : string  }))</pre> n/a yes description Project description <code>string</code> n/a yes name Project name <code>string</code> n/a yes namespace Project namespace <code>string</code> n/a yes namespaces K8s namespaces where the project would be able to access <code>list(string)</code> n/a yes repo_urls Git Repository URLs that will interact with the project <code>list(string)</code> n/a yes"},{"location":"terraform/modules/k8s/argocd/project/#outputs","title":"Outputs","text":"Name Description name Project name"},{"location":"terraform/modules/k8s/argocd/server/","title":"Server","text":""},{"location":"terraform/modules/k8s/argocd/server/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.7.4 helm ~&gt; 2.12.1 kubernetes ~&gt; 2.26.0"},{"location":"terraform/modules/k8s/argocd/server/#providers","title":"Providers","text":"Name Version helm ~&gt; 2.12.1 kubernetes ~&gt; 2.26.0"},{"location":"terraform/modules/k8s/argocd/server/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"terraform/modules/k8s/argocd/server/#resources","title":"Resources","text":"Name Type helm_release.argocd resource kubernetes_namespace.argocd resource kubernetes_secret.argo_token data source"},{"location":"terraform/modules/k8s/argocd/server/#inputs","title":"Inputs","text":"Name Description Type Default Required argocd_domain ArgoCD DNS name <code>string</code> n/a yes argocd_helm_chart_version ArgoCD Helm version at https://github.com/argoproj/argo-helm/releases <code>string</code> <code>\"6.4.0\"</code> no argocd_version Docker image tag to use for deployment - https://github.com/argoproj/argo-cd/releases <code>string</code> <code>\"v2.10.1\"</code> no name ArgoCD Cluster name <code>string</code> <code>\"argocd\"</code> no namespace K8s namespace to use <code>string</code> <code>\"argocd\"</code> no"},{"location":"terraform/modules/k8s/argocd/server/#outputs","title":"Outputs","text":"Name Description argocd_server ArgoCD Server Addr argocd_token ArgoCD Token namespace K8s namespace where ArgoCD server has been deployed"}]}